{"componentChunkName":"component---src-templates-post-js","path":"/posts/C-中的-StringTokenizer-类/","result":{"data":{"sitePage":{"id":"SitePage /posts/C-中的-StringTokenizer-类/"}},"pageContext":{"url":"/posts/C-中的-StringTokenizer-类/","relativePath":"posts/C-中的-StringTokenizer-类.md","relativeDir":"posts","base":"C-中的-StringTokenizer-类.md","name":"C-中的-StringTokenizer-类","frontmatter":{"title":"C# 中的 StringTokenizer 类","stackbit_url_path":"posts/C-中的-StringTokenizer-类","date":"2010-06-01 11:30:34","excerpt":"","comments_count":0,"positive_reactions_count":0,"tags":[null],"canonical_url":"https://be-net.azurewebsites.net/post/2010/06/01/C-中的-StringTokenizer-类","template":"post"},"html":"<pre><code>    &#x3C;p>在Java中，有一个StringTokenizer类，对于分析单词非常有用。&#x3C;/p>\n</code></pre>\n<p>C# 中，似乎没有系统自带的StringTokenizer类，不过，可以自己写一个。</p>\n<p>网上搜索到一个非常专业的代码。如下：</p>\n<pre class=\"brush: csharp\">\nusing System;\nusing System.Collections;\nusing System.Text;\n<p>/// &#x3C;summary>\n/// StringTokenizer. A String Tokenizer that accepts Strings as source and delimiter. Only 1 delimiter is supported (either String or char[]).\n/// &#x3C;/summary>\npublic class StringTokenizer\n{\nprivate int curIndex;\nprivate int numTokens;\nprivate ArrayList tokens;\nprivate string source;\nprivate string delimiter;</p>\n<pre><code>/// &#x26;lt;summary&#x26;gt;\n/// Constructor for StringTokenizer Class.\n/// &#x26;lt;/summary&#x26;gt;\n/// \n/// The Source String. \n/// The Delimiter String. If a 0 length delimiter is given, \" \" (space) is used by default.\n///\npublic StringTokenizer(string source, string delimiter)\n{\n    this.tokens = new ArrayList(10);\n    this.source = source;\n    this.delimiter = delimiter;\n\n    if (delimiter.Length &#x26;lt;= 0)\n    {\n        this.delimiter = \" \";\n    }\n    this.Tokenize();\n}\n\n///\n/// Constructor for StringTokenizer Class.\n/// \n/// The Source String.\n/// The Delimiter String as a char[]. Note that this is converted into a single String and expects Unicode encoded chars.\n/// \npublic StringTokenizer(string source, char[] delimiter)\n    : this(source, new string(delimiter))\n{\n}\n\n///\n/// Constructor for StringTokenizer Class. The default delimiter of \" \" (space) is used.\n/// \n/// The Source String.\n/// \npublic StringTokenizer(string source)\n    : this(source, \"\")\n{\n}\n\n///\n/// Empty Constructor. Will create an empty StringTokenizer with no source, no delimiter, and no tokens.\n/// If you want to use this StringTokenizer you will have to call the NewSource(string s) method. You may\n/// optionally call the NewDelim(string d) or NewDelim(char[] d) methods if you don't with to use the default\n/// delimiter of \" \" (space).\n/// \npublic StringTokenizer()\n    : this(\"\", \"\")\n{\n\n}\n\nprivate void Tokenize()\n{\n    string tempSource = this.source;\n    string tok = \"\";\n    this.numTokens = 0;\n    this.tokens.Clear();\n    this.curIndex = 0;\n\n    if (tempSource.IndexOf(this.delimiter) &#x26;lt; 0 &#x26;amp;&#x26;amp; tempSource.Length &#x26;gt; 0) {\n        this.numTokens = 1;\n        this.curIndex = 0;\n        this.tokens.Add(tempSource);\n        this.tokens.TrimToSize();\n        tempSource = \"\";\n    }\n    else if (tempSource.IndexOf(this.delimiter) &#x26;lt; 0 &#x26;amp;&#x26;amp; tempSource.Length &#x26;lt;= 0)\n    {\n        this.numTokens = 0;\n        this.curIndex = 0;\n        this.tokens.TrimToSize();\n    }\n    while (tempSource.IndexOf(this.delimiter) &#x26;gt;= 0)\n    {\n        // Delimiter at beginning of source String.\n        if (tempSource.IndexOf(this.delimiter) == 0)\n        {\n            if (tempSource.Length &#x26;gt; this.delimiter.Length)\n            {\n                tempSource = tempSource.Substring(this.delimiter.Length);\n            }\n            else\n            {\n                tempSource = \"\";\n            }\n        }\n        else\n        {\n            tok = tempSource.Substring(0, tempSource.IndexOf(this.delimiter));\n            this.tokens.Add(tok);\n            if (tempSource.Length &#x26;gt; (this.delimiter.Length + tok.Length))\n            {\n                tempSource = tempSource.Substring(this.delimiter.Length + tok.Length);\n            }\n            else\n            {\n                tempSource = \"\";\n            }\n        }\n    }\n    // we may have a string leftover.\n    if (tempSource.Length &#x26;gt; 0)\n    {\n        this.tokens.Add(tempSource);\n    }\n    this.tokens.TrimToSize();\n    this.numTokens = this.tokens.Count;\n}\n\n///\n/// Method to add or change this Instance's Source string. The delimiter will remain the same (either default of \" \" (space) or whatever you \n/// constructed this StringTokenizer with or added with NewDelim(string d) or NewDelim(char[] d) ).\n/// \n/// The new Source String.\n///\npublic void NewSource(string newSource)\n{\n    this.source = newSource;\n    this.Tokenize();\n}\n\n///\n/// Method to add or change this Instance's Delimiter string. The source string will remain the same (either empty if you used Empty Constructor, or \n/// the previous value of source from the call to a parameterized constructor or NewSource(string s) ).\n/// \n/// The new Delimiter String\n/// \npublic void NewDelim(string newDel)\n{\n    if (newDel.Length == 0)\n    {\n        this.delimiter = \" \";\n    }\n    else\n    {\n        this.delimiter = newDel;\n    }\n    this.Tokenize();\n}\n\n///\n/// Method to add or change this Instance's Delimiter string. The source string will remain the same (either empty if you used Empty Constructor, or \n/// the previous vlaue of source from the call to a parameterized constructor or NewSource(string s) ).\n/// \n/// The New Delimiter as a char[]. Note that this is converted into a single String and expects Unicode encoded chars.\n/// \npublic void NewDelim(char[] newDel)\n{\n    string temp = new String(newDel);\n    if (temp.Length == 0)\n    {\n        this.delimiter = \" \";\n    }\n    else\n    {\n        this.delimiter = temp;\n    }\n    this.Tokenize();\n}\n\n///\n/// Method to get the number of tokens in this StringTokenizer.\n/// \n/// The number fo Tokens in the internal ArrayList.\n///\npublic int CountTokens()\n{\n    return this.tokens.Count;\n}\n\n///\n/// Method to probe for more tokens.\n/// \n/// true if there are more tokens; false otherwise.\n/// \npublic bool HasMoreTokens() {\n    if (this.curIndex &#x26;lt;= (this.tokens.Count -1)) {\n        return true;\n    } else {\n        return false;\n    }\n}\n\n///\n/// Method to get the next (string) token of this StringTokenizer.\n/// \n/// A string representing the next token; null if no tokens or more tokens.\n/// \npublic string NextToken() {\n    string returnString = \"\";\n    if (this.curIndex &#x26;lt;= this.tokens.Count -1) {\n        returnString = (string)tokens[curIndex];\n        this.curIndex ++;\n        return returnString;\n    } else {\n        return null;\n    }\n}\n\n///\n/// Gets the Source string of this StringTokenizer.\n/// \n/// A string representing the current Source.\n/// \npublic string Source {\n    get {\n        return this.source;\n    }\n}\n\n///\n/// Gets the Delimiter string of this StringTokenizer.\n/// \n/// A string representing the current Delimiter.\n/// \npublic string Delimeter {\n    get {\n        return this.delimiter;\n    }\n}\n\n///\n/// Gets the tokens of this StringTokenizer.\n</code></pre>\n<p>    ///\n    /// 涂鸦添加此属性过程，以便调用。\n///\npublic ArrayList Tokens {\nget {\nreturn this.tokens;\n}\n}\n}\n</pre></p>\n<div>&nbsp;</div>","pages":[],"site":{"siteMetadata":{"title":"Jeff Tian","author":"@zizhujy","description":"A wild full stack developer","palette":"yellow","header":{"title":"Jeff Tian","tagline":"A wild developer","logo_img":"https://images.ctfassets.net/qixg1o8tujmf/7z1ua3nTOC5B7DwwzAki8I/4e1a05f8db770c285a492eeb1eaa398f/imageedit_3_2509022194.png","background_img":"https://images.ctfassets.net/qixg1o8tujmf/7m0jrKYaDBwEvlc5lo8nt6/6d50a5050d9cdc0d4d2047e35feac292/10648733_696750647079056_2800539603462658695_o.jpg","has_nav":true,"nav_links":[{"label":"Home","url":"/","style":"link","type":"action"},{"label":"About","url":"/about","style":"link","type":"action"},{"label":"关于","url":"https://ggyy.pa-pa.me/about","style":"link","icon_class":"lorem-ipsum","new_window":true,"type":"action"},{"label":"Contact","url":"/contact","style":"link","type":"action"},{"label":"Support Me","url":"/support-me","style":"link","type":"action"},{"label":"叽叽歪歪","url":"https://ggyy.pa-pa.me/","style":"link","icon_class":"lorem-ipsum","new_window":true,"type":"action"}],"has_social":true,"social_links":[{"label":"Twitter","url":"https://twitter.com/zizhujy","style":"icon","icon_class":"fa-twitter","new_window":true,"type":"action"},{"label":"Instagram","url":"https://www.instagram.com/jefftian5","style":"icon","icon_class":"fa-instagram","new_window":true,"type":"action"},{"label":"GitHub","url":"https://github.com/jeff-tian","style":"icon","icon_class":"fa-github","new_window":true,"type":"action"},{"label":"LinkedIn","url":"https://www.linkedin.com/jeff~tian","style":"icon","icon_class":"fa-linkedin","new_window":true,"type":"action"},{"label":"DEV","url":"https://dev.to/jefftian","style":"icon","icon_class":"fa-dev","new_window":true,"type":"action"},{"label":"知乎","url":"https://www.zhihu.com/people/jefftian","style":"icon","icon_class":"fa-zhihu","new_window":true,"type":"action"}],"type":"header"},"footer":{"content":"&copy; All rights reserved.","links":[{"label":"Made with Stackbit.","url":"https://www.stackbit.com","style":"link","new_window":true,"type":"action"},{"label":"紫竹叽歪","url":"https://zizhujy.apphb.com","style":"link","icon_class":"http://zizhujy.apphb.com/Content/Images/logo.png","new_window":true,"type":"action"}],"type":"footer"}},"pathPrefix":"","data":{"data":{"author":{"name":"Jeff Tian","avatar":"https://res.cloudinary.com/practicaldev/image/fetch/s--a5qDZLv3--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/318420/3bfd2d99-430c-4049-8dd5-e2adc961e1e0.png"},"social":{"devto":{"username":"jefftian"},"twitter":{"username":"zizhujy"},"github":{"username":"Jeff-Tian"}}}}}}},"staticQueryHashes":[],"slicesMap":{}}